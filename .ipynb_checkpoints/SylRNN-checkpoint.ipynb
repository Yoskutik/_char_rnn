{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.metrics import top_k_categorical_accuracy\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.nn import weighted_cross_entropy_with_logits\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.data import Dataset\n",
    "\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = ['\\u200e', '[', ']', '(', ')', '\\x98', '́', '\\r']\n",
    "replace = {\n",
    "    '»': '\"',\n",
    "    '«': '\"',\n",
    "    '“': '\"',\n",
    "    '„': '\"',\n",
    "    '...': '…',\n",
    "}\n",
    "\n",
    "def preprocess_str(string):\n",
    "    string = string.lower()\n",
    "    for x in remove:\n",
    "        string = string.replace(x, '')\n",
    "    for key, value in replace.items():\n",
    "        string = string.replace(key, value)\n",
    "    string = re.sub(r' +', ' ', string)\n",
    "    string = string.replace('\\n ', '\\n')\n",
    "    string = re.sub(r'[. ]{2,}', '. ', string)\n",
    "    return string\n",
    "\n",
    "chars = set()\n",
    "for path in glob.glob('poems/*.txt'):\n",
    "    with open(path, 'rb') as f:\n",
    "        text = preprocess_str(f.read().decode('utf-8'))\n",
    "    chars.update(list(text))\n",
    "\n",
    "corpus = {value: i for i, value in enumerate(sorted(chars))}\n",
    "corpus_inv = {value: key for key, value in corpus.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 100\n",
    "min_chars = 50\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего прочитано сивмолов: 442263\n",
      "Всего прочитано слов: 55780\n"
     ]
    }
   ],
   "source": [
    "def read_n_poems(n=None):\n",
    "    text = ''\n",
    "    for path in glob.glob('poems/*.txt')[:n]:\n",
    "        with open(path, 'rb') as f:\n",
    "            text += preprocess_str(f.read().decode('utf-8'))\n",
    "            \n",
    "    total_chars = len(text)\n",
    "    total_words = len(text.split(' '))\n",
    "    text_as_int = [corpus[c] for c in text]\n",
    "    \n",
    "    ds = Dataset.from_tensor_slices(text_as_int)\n",
    "    ds = ds.batch(window_size + 1, drop_remainder=True).map(lambda x: (x[:-1], x[1:]))\n",
    "    \n",
    "    print(f'Всего прочитано сивмолов: {total_chars}')\n",
    "    print(f'Всего прочитано слов: {total_words}')\n",
    "    \n",
    "    return ds.shuffle(8096).batch(batch_size, drop_remainder=True)\n",
    "\n",
    "dataset = read_n_poems()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(batch_size):\n",
    "    return Sequential([\n",
    "        Embedding(len(corpus), 256, batch_input_shape=[batch_size, None]),\n",
    "        LSTM(1024, return_sequences=True, stateful=True),\n",
    "        Dense(len(corpus)),\n",
    "    ])\n",
    "\n",
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "model = build_model(batch_size)\n",
    "model.compile('adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "history = model.fit(\n",
    "    dataset,\n",
    "    epochs=20,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join('training_checkpoints', 'ckpt_{epoch}'),\n",
    "            save_weights_only=True,\n",
    "        )\n",
    "    ],\n",
    "    verbose=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(1)\n",
    "model.load_weights(tf.train.latest_checkpoint('training_checkpoints'))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    num_generate = 500\n",
    "    input_eval = [corpus[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    text_generated = []\n",
    "    model.reset_states()\n",
    "    \n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predictions *= 1\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(corpus_inv[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ай-чалься царого,\n",
      "кого в блещет пустынными думая, гордости ударит;\n",
      "но еду ли весны, ты снова доржен.\n",
      "не ль блажен ов нем торзою —\n",
      "не знал любви —\n",
      "и тень кружить отоспеси;\n",
      "как.\n",
      "прости, взгляну черней зара в\n",
      "востих обходят, можгорец\n",
      "в графодской минуты певец,\n",
      "мир воинственные детра в рощах досужиеб развялох, пью здавись и прекрасной\n",
      "он блажен, как луна, уж пальбины,\n",
      "иль трепетный холодной могила,\n",
      "и, проть тя.кто с киним, вянет лико нас окно\n",
      "останонь дворя - и шум призывали\n",
      "утохлат; на зарею велечая\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, \"а\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
